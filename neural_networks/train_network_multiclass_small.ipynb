{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Multisegmentaion Network\n",
    "by DevNesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.losses import *\n",
    "import skimage.io as io\n",
    "import skimage.transform as tr\n",
    "import skimage.color\n",
    "import dask.array as da\n",
    "from glob import glob\n",
    "from dask.array.image import imread\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "from helper import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reads more that one mask as ground truth \n",
    "def read_masks(path, size):\n",
    "    imgs = []\n",
    "    paths = glob(path)\n",
    "    index = 0\n",
    "    for p in paths:\n",
    "        \n",
    "        # mask1\n",
    "        mask1 = read_img(p, (224,224,1))\n",
    "        mask1 = np.array(mask1)\n",
    "        mask1[mask1[:,:,0] > 0.001] = 1\n",
    "        \n",
    "        # mask2\n",
    "        p2 = p.replace(\"masks_01\",\"masks_02\")\n",
    "        mask2 = read_img(p2, (224,224,1))\n",
    "        mask2 = np.array(mask2)\n",
    "        mask2[mask2[:,:,0] > 0.001] = 1\n",
    "        \n",
    "        # mask3\n",
    "        p3 = p.replace(\"masks_01\",\"masks_03\")\n",
    "        mask3 = read_img(p3, (224,224,1))\n",
    "        mask3 = np.array(mask3)\n",
    "        mask3[mask3[:,:,0] > 0.001] = 1\n",
    "        \n",
    "        # concatenation\n",
    "        masks = np.concatenate([mask1, mask2, mask3], axis=2)\n",
    "        \n",
    "        imgs.append(masks)\n",
    "        index += 1\n",
    "        if (index % 200 == 0):\n",
    "            print(index)\n",
    "    return np.array(imgs)\n",
    "\n",
    "# Saves the data into a variable (x = input, y = masks / ground truth)\n",
    "x = None\n",
    "x = read_imgs('/home/dan/Desktop/combined_masks/images/data/*.png', (224,224,1))\n",
    "y = None\n",
    "y = read_masks('/home/dan/Desktop/combined_masks/masks_01/data/*.png', (224,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the masks in jupyter notebook for comparison\n",
    "i = 4\n",
    "\n",
    "# Input \n",
    "plt.imshow([i][:,:,0], cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "# Ground Truth Mask1\n",
    "plt.imshow(y[i][:,:,0], cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "# Ground Truth Mask2 \n",
    "plt.imshow(y[i][:,:,1], cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "# Ground Truth Mask3\n",
    "plt.imshow(y[i][:,:,2], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model \n",
    "from keras.models import load_model\n",
    "model = load_model('modelsave2.h5', custom_objects={'iou_loss': f1_loss})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "model = None\n",
    "model = UNet((224,224,1), 3, 16, 4, 2.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks\n",
    "earlyStop = EarlyStopping(monitor='val_loss', patience = 5)\n",
    "checkpoint = ModelCheckpoint('training_multi_best5.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss=f1_loss, metrics=[iou_loss, precision, error,recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = 2450 # = 80% of all given data\n",
    "result = model.fit(x[:train], y[:train], batch_size=32, epochs=20,\n",
    "         validation_data=(x[train:], y[train:]), shuffle=True, callbacks=[earlyStop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list data from history\n",
    "print(result.history.keys())\n",
    "\n",
    "# plot graph for loss \n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('model loss') # name of graph\n",
    "plt.ylabel('loss')  #name of y-axis\n",
    "plt.xlabel('epoch') #name of x-axis\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# list all information\n",
    "print(result.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('training_multi5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = read_imgs('/home/dan/Desktop/multipredict/test/images/data/*.png', (224,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a prediction for the whole dataset\n",
    "pred = model.predict(testdata, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the prediction in jupyter notebook for comparison\n",
    "i = 13\n",
    "\n",
    "# Input Picture\n",
    "plt.imshow(testdata[i, ..., 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(pred[i])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Prediction Dim 0\n",
    "plt.imshow(pred[i][:,:,0], cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Prediction Dim 1\n",
    "plt.imshow(pred[i][:,:,1], cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Prediction Dim 1\n",
    "plt.imshow(pred[i][:,:,2], cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
